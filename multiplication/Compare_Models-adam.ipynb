{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create object to automated model comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import arithmetic_datasets as ad\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelComparator\n",
    "\n",
    "```\n",
    "mc = ModelComparator()\n",
    "mc.add_model(name, model)\n",
    "mc.add_training_set(name, data)\n",
    "\n",
    "mc.train_models(epochs, batches, **kwargs)\n",
    "\n",
    "mc.compare_min(metric)\n",
    "mc.compare_max(metric)\n",
    "\n",
    "mc.history_for(model_name, training_set_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelComparator:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.training_sets = {}\n",
    "        self.histories = {}\n",
    "    \n",
    "    def add_model(self, name, model):\n",
    "        self.models[name] = model\n",
    "    \n",
    "    def add_training_set(self, name, data):\n",
    "        self.training_sets[name] = data\n",
    "        \n",
    "    def train_models(self, **kwargs):\n",
    "        for model_name in self.models:\n",
    "            for tset_name in self.training_sets:\n",
    "                print(f\"MODEL {model_name} TRAINING ON DATASET {tset_name}\")\n",
    "                \n",
    "                model = self.models[model_name]()\n",
    "                \n",
    "                history = model.fit(\n",
    "                    self.training_sets[tset_name][0], self.training_sets[tset_name][1],\n",
    "                    **kwargs\n",
    "                )\n",
    "                \n",
    "                self.histories[(model_name, tset_name)] = history\n",
    "    \n",
    "    def compare_min(self, metric):\n",
    "        result = {}\n",
    "        minimum = None\n",
    "        min_name = None\n",
    "        for hkey in self.histories:\n",
    "            history = self.histories[hkey].history\n",
    "            result[hkey] = np.amin(history[metric])\n",
    "            if minimum == None or minimum >= result[hkey]:\n",
    "                minimum = result[hkey]\n",
    "                min_name = hkey\n",
    "        return result, {\"name\" : min_name, \"value\":minimum}\n",
    "            \n",
    "    \n",
    "    def compare_max(self, metric):\n",
    "        result = {}\n",
    "        maximum = None\n",
    "        max_name = None\n",
    "        for hkey in self.histories:\n",
    "            history = self.histories[hkey].history\n",
    "            result[hkey] = np.amax(history[metric])\n",
    "            if maximum == None or maximum >= result[hkey]:\n",
    "                maximum = result[hkey]\n",
    "                max_name = hkey\n",
    "        return result, {\"name\" : max_name, \"value\": maximum}\n",
    "    \n",
    "    def history_for(self, model_name, training_set_name):\n",
    "        return self.histories[(model_name, training_set_name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nondense_model():\n",
    "    # Input layer of 3 neurons \n",
    "    inp = Input(shape=(1,3))\n",
    "    \n",
    "    #128 layer\n",
    "    d2_out = Dense(128)(inp)\n",
    "\n",
    "    #grab first, 2nd half of the 128 layer\n",
    "    d2_out_p1 = Lambda(lambda x: x[:,:,0:64])(d2_out)\n",
    "    d2_out_p2 = Lambda(lambda x: x[:,:,64:128])(d2_out)\n",
    "\n",
    "    #64 layer(s)\n",
    "    d3_out = Dense(64)(d2_out_p1)\n",
    "    d4_out = Dense(64)(d2_out_p2)\n",
    "\n",
    "    #grab output nodes from both 64 layers\n",
    "    d5_out = concatenate([d3_out, d4_out])\n",
    "    \n",
    "    o = Dense(1)(d5_out)\n",
    "    \n",
    "    model = Model(inp, o)\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(\n",
    "        loss=\"MeanSquaredError\",\n",
    "        metrics = [\"accuracy\"],\n",
    "        optimizer = opt\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "def dense_model_5L():\n",
    "    model_5layer = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(1024, input_shape=(1,3)),\n",
    "        tf.keras.layers.Dense(512),\n",
    "        tf.keras.layers.Dense(256),\n",
    "        tf.keras.layers.Dense(128),\n",
    "        tf.keras.layers.Dense(64),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(\n",
    "        loss=\"MeanSquaredError\",\n",
    "        metrics = [\"accuracy\"],\n",
    "        optimizer = opt\n",
    "    )\n",
    "    \n",
    "\n",
    "    return model_5layer\n",
    "\n",
    "def dense_model2():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(2048, input_shape=(1,3)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1024))\n",
    "    model.add(tf.keras.layers.Dense(512))\n",
    "    model.add(tf.keras.layers.Dense(256))\n",
    "    model.add(tf.keras.layers.Dense(64))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(\n",
    "        loss=\"MeanSquaredError\",\n",
    "        metrics = [\"accuracy\"],\n",
    "        optimizer = opt\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_examples = 20000\n",
    "rstart = 1\n",
    "rend = 10000\n",
    "\n",
    "# MULT\n",
    "mult_setX, mult_setY = ad.gen_data_mult(num_examples, rstart, rend)\n",
    "mult_setX = mult_setX.reshape(num_examples, 1, 3)\n",
    "\n",
    "# LOG(MULT)\n",
    "mult_logX = np.log(mult_setX)\n",
    "mult_logY = np.log(mult_setY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ModelComparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelComparator()\n",
    "\n",
    "mc.add_model(\"nondense_model\", nondense_model)\n",
    "mc.add_model(\"dense_model\", dense_model_5L)\n",
    "mc.add_model(\"dense_model v2\", dense_model2)\n",
    "\n",
    "mc.add_training_set(\"log normal multiply\", (mult_logX, mult_logY))\n",
    "mc.add_training_set(\"multiplication\", (mult_setX, mult_setY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL nondense_model TRAINING ON DATASET log normal multiply\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Could not interpret optimizer identifier:', <keras.optimizers.Adam object at 0x000002107A774460>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8f6c65be4a64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m mc.train_models(\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-1b33d3e5368f>\u001b[0m in \u001b[0;36mtrain_models\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"MODEL {model_name} TRAINING ON DATASET {tset_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 history = model.fit(\n",
      "\u001b[1;32m<ipython-input-3-522248cb5309>\u001b[0m in \u001b[0;36mnondense_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     model.compile(\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"MeanSquaredError\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_eagerly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run_eagerly'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m       self.compiled_loss = compile_utils.LossesContainer(\n\u001b[0;32m    330\u001b[0m           loss, loss_weights, output_names=self.output_names)\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_get_optimizer\u001b[1;34m(self, optimizer)\u001b[0m\n\u001b[0;32m    348\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_get_single_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_get_single_optimizer\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_single_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m       \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m       if (self._dtype_policy.loss_scale is not None and\n\u001b[0;32m    346\u001b[0m           not isinstance(opt, lso.LossScaleOptimizer)):\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 902\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Could not interpret optimizer identifier:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: ('Could not interpret optimizer identifier:', <keras.optimizers.Adam object at 0x000002107A774460>)"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "batch_size = num_examples\n",
    "\n",
    "mc.train_models(\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare min loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_min_loss, min_loss = mc.compare_min(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_min_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
