{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create object to automated model comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arithmetic_datasets as ad\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Metric\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback Directory Filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WIP\n",
    "cb_filepath = \"checkpoints\"\n",
    "if not os.path.exists(cb_filepath):\n",
    "    os.makedirs(cb_filepath)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveModelCallback(Callback):\n",
    "    def __init__(self, filepath,  n=100):\n",
    "        super(SaveModelCallback, self).__init__()\n",
    "        self.num_epochs = 100\n",
    "        self.filepath = filepath\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        super(SaveModelCallback, self).on_epoch_end(epoch, logs)\n",
    "        if epoch % 100 == 0:\n",
    "            self.model.save(f\"{self.filepath}/{self.model.name}/{epoch}.model\")\n",
    "            print(f\"model saved: {self.filepath}/{self.model.name}/{epoch}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "smc = SaveModelCallback(cb_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelComparator\n",
    "\n",
    "```\n",
    "mc = ModelComparator()\n",
    "mc.add_model(name, model)\n",
    "mc.add_training_set(name, data)\n",
    "\n",
    "mc.train_models(epochs, batches, **kwargs)\n",
    "\n",
    "mc.compare_min(metric)\n",
    "mc.compare_max(metric)\n",
    "\n",
    "mc.history_for(model_name, training_set_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelComparator:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.training_sets = {}\n",
    "        self.histories = {}\n",
    "    \n",
    "    def add_model(self, name, model):\n",
    "        self.models[name] = model\n",
    "    \n",
    "    def add_training_set(self, name, data):\n",
    "        self.training_sets[name] = data\n",
    "            \n",
    "    def train_models(self, **kwargs):\n",
    "        for model_name in self.models:\n",
    "            for tset_name in self.training_sets:\n",
    "                print(f\"MODEL {model_name} TRAINING ON DATASET {tset_name}\")\n",
    "                \n",
    "                model = self.models[model_name]()\n",
    "                \n",
    "                history = model.fit(\n",
    "                    self.training_sets[tset_name][0], self.training_sets[tset_name][1],\n",
    "                    **kwargs\n",
    "                )\n",
    "\n",
    "                self.histories[(model_name, tset_name)] = history\n",
    "                \n",
    "    def compare_min(self, metric):\n",
    "        result = {}\n",
    "        minimum = None\n",
    "        min_name = None\n",
    "        for hkey in self.histories:\n",
    "            history = self.histories[hkey].history\n",
    "            result[hkey] = np.amin(history[metric])\n",
    "            if minimum == None or minimum >= result[hkey]:\n",
    "                minimum = result[hkey]\n",
    "                min_name = hkey\n",
    "        return result, {\"name\" : min_name, \"value\":minimum}\n",
    "            \n",
    "    \n",
    "    def compare_max(self, metric):\n",
    "        result = {}\n",
    "        maximum = None\n",
    "        max_name = None\n",
    "        for hkey in self.histories:\n",
    "            history = self.histories[hkey].history\n",
    "            result[hkey] = np.amax(history[metric])\n",
    "            if maximum == None or maximum >= result[hkey]:\n",
    "                maximum = result[hkey]\n",
    "                max_name = hkey\n",
    "        return result, {\"name\" : max_name, \"value\": maximum}\n",
    "    \n",
    "    def history_for(self, model_name, training_set_name):\n",
    "        return self.histories[(model_name, training_set_name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nondense_model():\n",
    "    model_name = \"nondense_model\"\n",
    "    \n",
    "    if not os.path.exists(cb_filepath + \"/\" + model_name):\n",
    "        os.makedirs(cb_filepath + \"/\" + model_name)  \n",
    "    \n",
    "    checkpoints = [cb_filepath + '/' + model_name + \"/\" + name\n",
    "                   for name in os.listdir(cb_filepath + \"/\" + model_name)]\n",
    "    if checkpoints:\n",
    "        latest_cp = max(checkpoints, key=os.path.getctime )\n",
    "        print('Restoring from', latest_cp)\n",
    "        return load_model(latest_cp)\n",
    "    \n",
    "    # Input layer of 3 neurons \n",
    "    inp = Input(shape=(1,3))\n",
    "    \n",
    "    #128 layer\n",
    "    d2_out = Dense(128)(inp)\n",
    "\n",
    "    #grab first, 2nd half of the 128 layer\n",
    "    d2_out_p1 = Lambda(lambda x: x[:,:,0:64])(d2_out)\n",
    "    d2_out_p2 = Lambda(lambda x: x[:,:,64:128])(d2_out)\n",
    "\n",
    "    #64 layer(s)\n",
    "    d3_out = Dense(64)(d2_out_p1)\n",
    "    d4_out = Dense(64)(d2_out_p2)\n",
    "\n",
    "    #grab output nodes from both 64 layers\n",
    "    d5_out = concatenate([d3_out, d4_out])\n",
    "    \n",
    "    o = Dense(1)(d5_out)\n",
    "    \n",
    "    model = Model(inp, o)\n",
    "    \n",
    "    model._name = model_name\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"MeanSquaredError\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def dense_model_5L():\n",
    "    model_name = \"dense_model_5L\"\n",
    "    \n",
    "    if not os.path.exists(cb_filepath + \"/\" + model_name):\n",
    "        os.makedirs(cb_filepath + \"/\" + model_name)  \n",
    "    \n",
    "    checkpoints = [cb_filepath + '/' + model_name + \"/\" + name\n",
    "                   for name in os.listdir(cb_filepath + \"/\" + model_name)]\n",
    "    if checkpoints:\n",
    "        latest_cp = max(checkpoints, key=os.path.getctime )\n",
    "        print('Restoring from', latest_cp)\n",
    "        return load_model(latest_cp)\n",
    "    \n",
    "    model_5layer = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(1024, input_shape=(1,3)),\n",
    "        tf.keras.layers.Dense(512),\n",
    "        tf.keras.layers.Dense(256),\n",
    "        tf.keras.layers.Dense(128),\n",
    "        tf.keras.layers.Dense(64),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "#     model.name = \"dense_model\"\n",
    "\n",
    "    model_5layer._name = model_name\n",
    "    model_5layer.compile(\n",
    "        loss=\"MeanSquaredError\",\n",
    "        metrics=['accuracy'] #Acc not working, in testing\n",
    "    )\n",
    "\n",
    "    return model_5layer\n",
    "\n",
    "def dense_model2():\n",
    "    model_name = \"dense_model2\"\n",
    "    \n",
    "    if not os.path.exists(cb_filepath + \"/\" + model_name):\n",
    "        os.makedirs(cb_filepath + \"/\" + model_name)  \n",
    "    \n",
    "    checkpoints = [cb_filepath + '/' + model_name + \"/\" + name\n",
    "                   for name in os.listdir(cb_filepath + \"/\" + model_name)]\n",
    "    if checkpoints:\n",
    "        latest_cp = max(checkpoints, key=os.path.getctime )\n",
    "        print('Restoring from', latest_cp)\n",
    "        return load_model(latest_cp)\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(2048, input_shape=(1,3)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1024))\n",
    "    model.add(tf.keras.layers.Dense(512))\n",
    "    model.add(tf.keras.layers.Dense(256))\n",
    "    model.add(tf.keras.layers.Dense(64))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    \n",
    "#     model.name = \"dense_model v2\"\n",
    "    model._name = model_name\n",
    "    model.compile(\n",
    "        loss=\"MeanSquaredError\",\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model():\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Input(shape=(1,2)))\n",
    "#     model.add(Dense(64))\n",
    "#     model.add(Dense(1))\n",
    "\n",
    "#     model.compile(\n",
    "#         loss=\"MeanSquaredError\",\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_examples = 20000\n",
    "rstart = 1\n",
    "rend = 10000\n",
    "\n",
    "# MULT\n",
    "mult_setX, mult_setY = ad.gen_data_mult(num_examples, rstart, rend)\n",
    "mult_setX = mult_setX.reshape(num_examples, 1, 3)\n",
    "\n",
    "# LOG(MULT)\n",
    "mult_logX = np.log(mult_setX)\n",
    "mult_logY = np.log(mult_setY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ModelComparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelComparator()\n",
    "\n",
    "mc.add_model(\"nondense_model\", nondense_model)\n",
    "mc.add_model(\"dense_model\", dense_model_5L)\n",
    "mc.add_model(\"dense_model v2\", dense_model2)\n",
    "\n",
    "mc.add_training_set(\"log normal multiply\", (mult_logX, mult_logY))\n",
    "mc.add_training_set(\"multiplication\", (mult_setX, mult_setY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data (Garbage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.ones((100,2))\n",
    "# y = np.ones((100,1))\n",
    "\n",
    "# model.fit(X, y, epochs=25, batch_size=1, callbacks=[smc])\n",
    "# model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"checkpoints/chkpt-20.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL nondense_model TRAINING ON DATASET log normal multiply\n",
      "Restoring from checkpoints/nondense_model/900.model\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 2707791872.0000 - accuracy: 0.0000e+00INFO:tensorflow:Assets written to: checkpoints/nondense_model/0.model\\assets\n",
      "model saved: checkpoints/nondense_model/0.model\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2707791872.0000 - accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2629778176.0000 - accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2574998272.0000 - accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2530174464.0000 - accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2491131904.0000 - accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2455942912.0000 - accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2423537408.0000 - accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2393251072.0000 - accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2364641280.0000 - accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2337393664.0000 - accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2311279872.0000 - accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2286125568.0000 - accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2261795584.0000 - accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2238183936.0000 - accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2215203328.0000 - accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2192784128.0000 - accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2170868480.0000 - accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2149405952.0000 - accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2128356992.0000 - accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2107685760.0000 - accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2087362048.0000 - accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2067360896.0000 - accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2047659264.0000 - accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2028237952.0000 - accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2009079424.0000 - accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1990169600.0000 - accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1971493760.0000 - accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1953041536.0000 - accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1934801408.0000 - accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1916764800.0000 - accuracy: 0.0000e+00\n",
      "MODEL nondense_model TRAINING ON DATASET multiplication\n",
      "Restoring from checkpoints/nondense_model/900.model\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 161923270180864.0000 - accuracy: 0.0000e+00INFO:tensorflow:Assets written to: checkpoints/nondense_model/0.model\\assets\n",
      "model saved: checkpoints/nondense_model/0.model\n",
      "1/1 [==============================] - 2s 2s/step - loss: 161923270180864.0000 - accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161845742665728.0000 - accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 161810493734912.0000 - accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161792340787200.0000 - accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161778013044736.0000 - accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161765212028928.0000 - accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161753333760000.0000 - accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161742176911360.0000 - accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 161731556933632.0000 - accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161721440272384.0000 - accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161711709487104.0000 - accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161702347800576.0000 - accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 995us/step - loss: 161693288103936.0000 - accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161684513619968.0000 - accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 161675990794240.0000 - accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161667686072320.0000 - accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 161659649785856.0000 - accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161652150370304.0000 - accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161646077018112.0000 - accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161644365742080.0000 - accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161646949433344.0000 - accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161639382908928.0000 - accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161624266637312.0000 - accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161611868274688.0000 - accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 161602640805888.0000 - accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 161594789068800.0000 - accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 161587440648192.0000 - accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161580410994688.0000 - accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161573515558912.0000 - accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 161566771118080.0000 - accuracy: 0.0000e+00\n",
      "MODEL dense_model TRAINING ON DATASET log normal multiply\n",
      "Restoring from checkpoints/dense_model_5L/200.model\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 2092261888.0000 - accuracy: 0.0000e+00INFO:tensorflow:Assets written to: checkpoints/dense_model_5L/0.model\\assets\n",
      "model saved: checkpoints/dense_model_5L/0.model\n",
      "1/1 [==============================] - 4s 4s/step - loss: 2092261888.0000 - accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 559067776.0000 - accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 353785600.0000 - accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 252821168.0000 - accuracy: 0.0000e+00\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 192038256.0000 - accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 151447952.0000 - accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 122533840.0000 - accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 101000816.0000 - accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 84433976.0000 - accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 71366944.0000 - accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 60856448.0000 - accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 52267820.0000 - accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 45158204.0000 - accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 39209276.0000 - accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 34186436.0000 - accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 29912990.0000 - accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 26253492.0000 - accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 23102354.0000 - accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 20376146.0000 - accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18008084.0000 - accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15944132.0000 - accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14140115.0000 - accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12559578.0000 - accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11172202.0000 - accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9952567.0000 - accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8879204.0000 - accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7933869.5000 - accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7100948.5000 - accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6367009.5000 - accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5720417.0000 - accuracy: 0.0000e+00\n",
      "MODEL dense_model TRAINING ON DATASET multiplication\n",
      "Restoring from checkpoints/dense_model_5L/200.model\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 144457500459008.0000 - accuracy: 0.0000e+00INFO:tensorflow:Assets written to: checkpoints/dense_model_5L/0.model\\assets\n",
      "model saved: checkpoints/dense_model_5L/0.model\n",
      "1/1 [==============================] - 3s 3s/step - loss: 144457500459008.0000 - accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 459244444844032.0000 - accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 144093082550272.0000 - accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 135121818615808.0000 - accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 133747370360832.0000 - accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 133526942908416.0000 - accuracy: 0.0000e+00\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-dd4b5a986f1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m mc.train_models(\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-422cc718d33b>\u001b[0m in \u001b[0;36mtrain_models\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 history = model.fit(\n\u001b[0m\u001b[0;32m     21\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtset_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtset_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                     \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "batch_size = num_examples\n",
    "\n",
    "mc.train_models(\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=[smc]\n",
    ")\n",
    "\n",
    "# new_model = dense_model_5L()\n",
    "# new_model = load_model(\"checkpoints/chkpt-200.model\")\n",
    "\n",
    "# new_model.predict(mult_logX)\n",
    "#new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare min loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_min_loss, min_loss = mc.compare_min(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_min_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
